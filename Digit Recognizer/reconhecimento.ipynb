{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "X_train = data.drop('label', axis = 1)\n",
    "X_train = X_train.values.reshape(-1,28,28,1)\n",
    "Y_train = data['label']\n",
    "test = pd.read_csv('test.csv')\n",
    "test = test.values.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train/255\n",
    "test = test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x241898d9160>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[3][:, :, 0], cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "Y_train = to_categorical(Y_train, num_classes = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 32, kernel_size = (3, 3),\n",
    "                 padding = 'Same', activation ='relu',\n",
    "                 input_shape = (28,28,1), strides = (1,1)))\n",
    "\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides = (2, 2)))\n",
    "\n",
    "model.add(Conv2D(filters = 2, kernel_size = (3, 3),\n",
    "                 padding = 'Same', activation = 'relu',\n",
    "                 input_shape = (14, 14, 32), strides = (1, 1)))\n",
    "\n",
    "model.add(MaxPool2D(pool_size = (2, 2) , strides = (2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "optmizer = optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=3, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/30\n",
      "37800/37800 [==============================] - 28s 740us/step - loss: 0.3653 - accuracy: 0.8883 - val_loss: 0.1870 - val_accuracy: 0.9464\n",
      "Epoch 2/30\n",
      "37800/37800 [==============================] - 31s 822us/step - loss: 0.2315 - accuracy: 0.9297 - val_loss: 0.1480 - val_accuracy: 0.9555\n",
      "Epoch 3/30\n",
      "37800/37800 [==============================] - 29s 769us/step - loss: 0.1915 - accuracy: 0.9420 - val_loss: 0.1238 - val_accuracy: 0.9633\n",
      "Epoch 4/30\n",
      "37800/37800 [==============================] - 28s 740us/step - loss: 0.1661 - accuracy: 0.9503 - val_loss: 0.1103 - val_accuracy: 0.9676\n",
      "Epoch 5/30\n",
      "37800/37800 [==============================] - 30s 796us/step - loss: 0.1559 - accuracy: 0.9533 - val_loss: 0.1076 - val_accuracy: 0.9667\n",
      "Epoch 6/30\n",
      "37800/37800 [==============================] - 27s 725us/step - loss: 0.1388 - accuracy: 0.9569 - val_loss: 0.1057 - val_accuracy: 0.9671\n",
      "Epoch 7/30\n",
      "37800/37800 [==============================] - 33s 877us/step - loss: 0.1325 - accuracy: 0.9602 - val_loss: 0.0914 - val_accuracy: 0.9736\n",
      "Epoch 8/30\n",
      "37800/37800 [==============================] - 27s 719us/step - loss: 0.1250 - accuracy: 0.9613 - val_loss: 0.0917 - val_accuracy: 0.9719\n",
      "Epoch 9/30\n",
      "37800/37800 [==============================] - 25s 659us/step - loss: 0.1183 - accuracy: 0.9643 - val_loss: 0.0838 - val_accuracy: 0.9731\n",
      "Epoch 10/30\n",
      "37800/37800 [==============================] - 25s 669us/step - loss: 0.1158 - accuracy: 0.9637 - val_loss: 0.0841 - val_accuracy: 0.9750\n",
      "Epoch 11/30\n",
      "37800/37800 [==============================] - 27s 719us/step - loss: 0.1084 - accuracy: 0.9660 - val_loss: 0.0813 - val_accuracy: 0.9750\n",
      "Epoch 12/30\n",
      "37800/37800 [==============================] - 32s 860us/step - loss: 0.1018 - accuracy: 0.9683 - val_loss: 0.0807 - val_accuracy: 0.9776\n",
      "Epoch 13/30\n",
      "37800/37800 [==============================] - 34s 901us/step - loss: 0.1040 - accuracy: 0.9677 - val_loss: 0.0773 - val_accuracy: 0.9769\n",
      "Epoch 14/30\n",
      "37800/37800 [==============================] - 32s 855us/step - loss: 0.0962 - accuracy: 0.9708 - val_loss: 0.0820 - val_accuracy: 0.9750\n",
      "Epoch 15/30\n",
      "37800/37800 [==============================] - 30s 793us/step - loss: 0.0941 - accuracy: 0.9698 - val_loss: 0.0800 - val_accuracy: 0.9755\n",
      "Epoch 16/30\n",
      "37800/37800 [==============================] - 33s 868us/step - loss: 0.0934 - accuracy: 0.9715 - val_loss: 0.0721 - val_accuracy: 0.9779\n",
      "Epoch 17/30\n",
      "37800/37800 [==============================] - 33s 872us/step - loss: 0.0925 - accuracy: 0.9710 - val_loss: 0.0730 - val_accuracy: 0.9774\n",
      "Epoch 18/30\n",
      "37800/37800 [==============================] - 34s 887us/step - loss: 0.0860 - accuracy: 0.9729 - val_loss: 0.0702 - val_accuracy: 0.9790\n",
      "Epoch 19/30\n",
      "37800/37800 [==============================] - 32s 860us/step - loss: 0.0883 - accuracy: 0.9724 - val_loss: 0.0748 - val_accuracy: 0.9779\n",
      "Epoch 20/30\n",
      "37800/37800 [==============================] - 29s 768us/step - loss: 0.0864 - accuracy: 0.9735 - val_loss: 0.0710 - val_accuracy: 0.9781\n",
      "Epoch 21/30\n",
      "37800/37800 [==============================] - 28s 745us/step - loss: 0.0831 - accuracy: 0.9742 - val_loss: 0.0694 - val_accuracy: 0.9786\n",
      "Epoch 22/30\n",
      "37800/37800 [==============================] - 29s 764us/step - loss: 0.0793 - accuracy: 0.9749 - val_loss: 0.0701 - val_accuracy: 0.9802\n",
      "Epoch 23/30\n",
      "37800/37800 [==============================] - 28s 748us/step - loss: 0.0780 - accuracy: 0.9753 - val_loss: 0.0690 - val_accuracy: 0.9795\n",
      "Epoch 24/30\n",
      "37800/37800 [==============================] - 28s 752us/step - loss: 0.0780 - accuracy: 0.9749 - val_loss: 0.0686 - val_accuracy: 0.9790\n",
      "Epoch 25/30\n",
      "37800/37800 [==============================] - 28s 749us/step - loss: 0.0751 - accuracy: 0.9763 - val_loss: 0.0692 - val_accuracy: 0.9805\n",
      "Epoch 26/30\n",
      "37800/37800 [==============================] - 28s 740us/step - loss: 0.0763 - accuracy: 0.9755 - val_loss: 0.0675 - val_accuracy: 0.9795\n",
      "Epoch 27/30\n",
      "37800/37800 [==============================] - 27s 702us/step - loss: 0.0745 - accuracy: 0.9762 - val_loss: 0.0666 - val_accuracy: 0.9802\n",
      "Epoch 28/30\n",
      "37800/37800 [==============================] - 28s 752us/step - loss: 0.0706 - accuracy: 0.9778 - val_loss: 0.0650 - val_accuracy: 0.9798\n",
      "Epoch 29/30\n",
      "37800/37800 [==============================] - 27s 706us/step - loss: 0.0692 - accuracy: 0.9781 - val_loss: 0.0657 - val_accuracy: 0.9807\n",
      "Epoch 30/30\n",
      "37800/37800 [==============================] - 35s 933us/step - loss: 0.0674 - accuracy: 0.9777 - val_loss: 0.0718 - val_accuracy: 0.9776\n"
     ]
    }
   ],
   "source": [
    "batch_size = 86\n",
    "epochs = 30\n",
    "history = model.fit(X_train, Y_train, batch_size = batch_size, epochs = epochs, \n",
    "                    validation_data = (X_val, Y_val), verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('modelo_treinado.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
