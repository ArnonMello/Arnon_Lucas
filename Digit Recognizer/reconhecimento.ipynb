{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "X_train = data.drop('label', axis = 1)\n",
    "X_train = X_train.values.reshape(-1,28,28,1)\n",
    "Y_train = data['label']\n",
    "test = pd.read_csv('test.csv')\n",
    "test = test.values.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train/255\n",
    "test = test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x226a3088e48>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[3][:, :, 0], cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "Y_train = to_categorical(Y_train, num_classes = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 32, kernel_size = (3, 3),\n",
    "                 padding = 'Same', activation ='relu',\n",
    "                 input_shape = (28,28,1), strides = (1,1)))\n",
    "\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides = (2, 2)))\n",
    "\n",
    "model.add(Conv2D(filters = 2, kernel_size = (3, 3),\n",
    "                 padding = 'Same', activation = 'relu',\n",
    "                 input_shape = (14, 14, 32), strides = (1, 1)))\n",
    "\n",
    "model.add(MaxPool2D(pool_size = (2, 2) , strides = (2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "optmizer = optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=3, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 37s 975us/step - loss: 0.0945 - accuracy: 0.9710 - val_loss: 0.0717 - val_accuracy: 0.9781\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 41s 1ms/step - loss: 0.0890 - accuracy: 0.9721 - val_loss: 0.0725 - val_accuracy: 0.9798\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 30s 788us/step - loss: 0.0895 - accuracy: 0.9733 - val_loss: 0.0803 - val_accuracy: 0.9755\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 36s 941us/step - loss: 0.0833 - accuracy: 0.9750 - val_loss: 0.0709 - val_accuracy: 0.9781\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 39s 1ms/step - loss: 0.0813 - accuracy: 0.9738 - val_loss: 0.0645 - val_accuracy: 0.9821\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 32s 848us/step - loss: 0.0806 - accuracy: 0.9755 - val_loss: 0.0686 - val_accuracy: 0.9788\n",
      "Epoch 7/10\n",
      "37800/37800 [==============================] - 32s 844us/step - loss: 0.0787 - accuracy: 0.9755 - val_loss: 0.0637 - val_accuracy: 0.9826\n",
      "Epoch 8/10\n",
      "37800/37800 [==============================] - 30s 790us/step - loss: 0.0738 - accuracy: 0.9763 - val_loss: 0.0607 - val_accuracy: 0.9826\n",
      "Epoch 9/10\n",
      "37800/37800 [==============================] - 27s 709us/step - loss: 0.0728 - accuracy: 0.9775 - val_loss: 0.0607 - val_accuracy: 0.9821\n",
      "Epoch 10/10\n",
      "37800/37800 [==============================] - 29s 768us/step - loss: 0.0743 - accuracy: 0.9768 - val_loss: 0.0599 - val_accuracy: 0.9838\n"
     ]
    }
   ],
   "source": [
    "batch_size = 86\n",
    "epochs = 10\n",
    "history = model.fit(X_train, Y_train, batch_size = batch_size, epochs = epochs, \n",
    "                    validation_data = (X_val, Y_val), verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def salvar_rede(model):\n",
    "    model_json = model.to_json()\n",
    "    with open(\"model.json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    # serialize weights to HDF5\n",
    "    model.save_weights(\"model.h5\")\n",
    "    print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "salvar_rede(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
